#!/usr/bin/env python3
"""
ç«å±±äº‘æ–‡æœ¬è½¬è¯­éŸ³æœåŠ¡ - ä¿®å¤ç‰ˆ
ä½¿ç”¨äºŒè¿›åˆ¶WebSocketåè®®å®ç°ï¼Œå®Œå…¨å…¼å®¹å®˜æ–¹ç¤ºä¾‹
"""

import os
import json
import time
import uuid
import asyncio
import logging
from typing import Optional, Dict, Any, List
from pathlib import Path

import websockets

from services.providers import TextToSpeechProvider
from protocols.volcengine_protocol import (
    Message, MsgType, EventType, MsgTypeFlagBits,
    start_connection,
    finish_connection,
    start_session,
    finish_session
)
from utils.provider_errors import ProviderError

logger = logging.getLogger(__name__)


class VolcengineTextToSpeech(TextToSpeechProvider):
    """ç«å±±äº‘TTSæä¾›è€… - äºŒè¿›åˆ¶WebSocketåè®®å®ç°"""
    
    def __init__(self, app_id: str, access_token: str):
        if not app_id or not access_token:
            raise ProviderError("ç«å±±äº‘TTSé…ç½®å‚æ•°ä¸å®Œæ•´")
        
        self.app_id = app_id
        self.access_token = access_token
        
        # WebSocketç«¯ç‚¹ï¼ˆäºŒè¿›åˆ¶åè®®ï¼‰
        self.ws_url = "wss://openspeech.bytedance.com/api/v1/tts/ws_binary"
        
        # æ”¯æŒçš„è¯­éŸ³ç±»å‹ï¼ˆç»è¿‡éªŒè¯çš„ï¼‰
        self.voice_types = {
            "zh": "zh_female_cancan_mars_bigtts",
            "en": "en_female_amanda_mars",
            "ja": "ja_female_nanami_mars",
            "ko": "ko_female_yeonhee_mars"
        }
        
        # é»˜è®¤é…ç½®
        self.sample_rate = 24000
        self.encoding = "wav"
        self.compression = "raw"
        self.speed_ratio = 1.0
        self.volume_ratio = 1.0
        self.pitch_ratio = 1.0
    
    def synthesize(self, text: str, language: str = "zh", 
                  output_path: Optional[str] = None, voice: Optional[str] = None) -> str:
        """åŒæ­¥æ¥å£ï¼šåˆæˆè¯­éŸ³"""
        try:
            # åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸­æ­£ç¡®å¤„ç†äº‹ä»¶å¾ªç¯
            try:
                # å°è¯•è·å–å½“å‰çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯
                loop = asyncio.get_running_loop()
                # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå™¨
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, 
                                           self._synthesize_async(text, language, output_path, voice))
                    return future.result()
            except RuntimeError:
                # å½“å‰çº¿ç¨‹æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                logger.debug("åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯ç”¨äºTTSåˆæˆ")
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    return loop.run_until_complete(
                        self._synthesize_async(text, language, output_path, voice)
                    )
                finally:
                    loop.close()
                    # æ¸…ç†äº‹ä»¶å¾ªç¯
                    asyncio.set_event_loop(None)
        except Exception as e:
            logger.error(f"TTSåˆæˆå¤±è´¥: {e}")
            raise ProviderError(f"TTSåˆæˆå¤±è´¥: {str(e)}")
    
    async def _synthesize_async(self, text: str, language: str, 
                               output_path: Optional[str], voice: Optional[str]) -> str:
        """å¼‚æ­¥åˆæˆå®ç°"""
        if not text:
            raise ProviderError("è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if not output_path:
            output_dir = Path("output")
            output_dir.mkdir(exist_ok=True)
            output_path = str(output_dir / f"tts_{int(time.time())}.wav")
        
        # é€‰æ‹©è¯­éŸ³ç±»å‹
        if not voice:
            voice = self.voice_types.get(language, self.voice_types["zh"])
        
        logger.info(f"ğŸš€ å¼€å§‹TTSåˆæˆ: {text[:50]}...")
        logger.info(f"ğŸ“ è¯­è¨€: {language}, è¯­éŸ³: {voice}")
        
        try:
            # å»ºç«‹WebSocketè¿æ¥
            headers = {
                "Authorization": f"Bearer;{self.access_token}"
            }
            
            async with websockets.connect(self.ws_url, additional_headers=headers, max_size=10 * 1024 * 1024) as websocket:
                # 1. å‘é€å¼€å§‹è¿æ¥æ¶ˆæ¯
                start_msg_data = start_connection()
                await websocket.send(start_msg_data)
                logger.debug("ğŸ“¤ å‘é€å¼€å§‹è¿æ¥æ¶ˆæ¯")
                
                # ç­‰å¾…è¿æ¥ç¡®è®¤
                response = await websocket.recv()
                msg = Message.from_bytes(response)
                if msg.event != EventType.ConnectionStarted:
                    raise ProviderError(f"è¿æ¥å¤±è´¥: {msg}")
                logger.debug("âœ… è¿æ¥å»ºç«‹æˆåŠŸ")
                
                # 2. å‘é€å¼€å§‹ä¼šè¯æ¶ˆæ¯
                session_id = str(uuid.uuid4())
                session_payload = {
                    "app": {
                        "appid": self.app_id,
                        "token": "access_token",
                        "cluster": "volcano_tts"
                    },
                    "user": {
                        "uid": "audio_translation_user"
                    },
                    "audio": {
                        "voice_type": voice,
                        "encoding": self.encoding,
                        "compression": self.compression,
                        "rate": self.sample_rate,
                        "speed_ratio": self.speed_ratio,
                        "volume_ratio": self.volume_ratio,
                        "pitch_ratio": self.pitch_ratio
                    },
                    "request": {
                        "text": text,
                        "text_type": "plain",
                        "operation": "submit"
                    }
                }
                
                session_msg_data = start_session(json.dumps(session_payload).encode(), session_id)
                await websocket.send(session_msg_data)
                logger.debug(f"ğŸ“¤ å‘é€ä¼šè¯è¯·æ±‚: {text[:30]}...")
                
                # 3. æ¥æ”¶éŸ³é¢‘æ•°æ®
                audio_chunks = []
                while True:
                    response = await websocket.recv()
                    msg = Message.from_bytes(response)
                    
                    if msg.type == MsgType.AudioOnlyServer:
                        # éŸ³é¢‘æ•°æ®
                        if msg.payload:
                            audio_chunks.append(msg.payload)
                            logger.debug(f"ğŸ“¥ æ¥æ”¶éŸ³é¢‘å—: {len(msg.payload)} å­—èŠ‚")
                    
                    elif msg.event == EventType.SessionFinished:
                        # ä¼šè¯ç»“æŸ
                        logger.debug("âœ… ä¼šè¯å®Œæˆ")
                        break
                    
                    elif msg.type == MsgType.Error:
                        # é”™è¯¯æ¶ˆæ¯
                        try:
                            error_info = json.loads(msg.payload.decode('utf-8'))
                        except:
                            error_info = msg.payload.decode('utf-8', 'ignore')
                        raise ProviderError(f"TTSé”™è¯¯: {error_info}")
                
                # 4. å‘é€ç»“æŸä¼šè¯æ¶ˆæ¯
                finish_msg_data = finish_session(session_id)
                await websocket.send(finish_msg_data)
                
                # 5. å‘é€ç»“æŸè¿æ¥æ¶ˆæ¯
                finish_conn_msg_data = finish_connection()
                await websocket.send(finish_conn_msg_data)
                
                # 6. ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                if audio_chunks:
                    audio_data = b''.join(audio_chunks)
                    with open(output_path, 'wb') as f:
                        f.write(audio_data)
                    
                    logger.info(f"âœ… TTSåˆæˆæˆåŠŸ: {output_path}")
                    logger.info(f"ğŸ“Š éŸ³é¢‘å¤§å°: {len(audio_data)} å­—èŠ‚")
                    return output_path
                else:
                    raise ProviderError("æœªæ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®")
                    
        except websockets.exceptions.WebSocketException as e:
            logger.error(f"WebSocketé”™è¯¯: {e}")
            raise ProviderError(f"WebSocketè¿æ¥å¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"TTSå¤„ç†é”™è¯¯: {e}")
            raise ProviderError(f"TTSå¤„ç†å¤±è´¥: {str(e)}")
    
    def synthesize_with_timestamps(self, text: str, language: str = "zh",
                                  output_path: Optional[str] = None) -> tuple:
        """åˆæˆè¯­éŸ³å¹¶è¿”å›æ—¶é—´æˆ³ä¿¡æ¯"""
        audio_path = self.synthesize(text, language, output_path)
        # ç®€åŒ–å®ç°ï¼Œè¿”å›å ä½æ—¶é—´æˆ³
        return audio_path, []
    
    def get_supported_voices(self, language: str) -> list:
        """è·å–æ”¯æŒçš„è¯­éŸ³åˆ—è¡¨"""
        if language in self.voice_types:
            return [self.voice_types[language]]
        return list(self.voice_types.values())
    
    def estimate_duration(self, text: str, language: str = "zh") -> float:
        """ä¼°ç®—è¯­éŸ³æ—¶é•¿"""
        # ç®€å•ä¼°ç®—ï¼šä¸­æ–‡æ¯ç§’3ä¸ªå­—ï¼Œè‹±æ–‡æ¯ç§’2.5ä¸ªè¯
        if language == "zh":
            return len(text) / 3.0
        else:
            words = text.split()
            return len(words) / 2.5
    
    def set_voice_parameters(self, speed: float = 1.0, pitch: float = 1.0, 
                            volume: float = 1.0):
        """è®¾ç½®è¯­éŸ³å‚æ•°"""
        self.speed_ratio = max(0.5, min(2.0, speed))
        self.pitch_ratio = max(0.5, min(2.0, pitch))
        self.volume_ratio = max(0.5, min(2.0, volume))
    
    def synthesize_speech(self, segments, language: str,
                         voice_config: Optional[Dict] = None,
                         match_original_timing: bool = True):
        """å®ç°æŠ½è±¡æ–¹æ³•ï¼šåˆæˆè¯­éŸ³"""
        from services.providers import SpeechSynthesisResult
        from models.core import TimedSegment
        import time
        
        # åˆå¹¶æ‰€æœ‰ç‰‡æ®µæ–‡æœ¬
        full_text = " ".join([seg.text for seg in segments])
        
        # åˆæˆè¯­éŸ³
        output_path = self.synthesize(full_text, language)
        
        # è¿”å›ç»“æœ
        return SpeechSynthesisResult(
            audio_file_path=output_path,
            total_duration=self.estimate_duration(full_text, language),
            segments_count=len(segments),
            processing_time=0.0,
            quality_score=1.0
        )
    
    def synthesize_text(self, text: str, language: str,
                       voice_config: Optional[Dict] = None) -> str:
        """å®ç°æŠ½è±¡æ–¹æ³•ï¼šåˆæˆå•ä¸ªæ–‡æœ¬çš„è¯­éŸ³"""
        return self.synthesize(text, language)
#!/usr/bin/env python3
"""
ç«å±±äº‘è¯­éŸ³è¯†åˆ«æœåŠ¡ - v3 APIå®žçŽ°
ä½¿ç”¨æœ€æ–°çš„v3 APIç«¯ç‚¹ï¼Œæ— å ä½ç¬¦
"""

import os
import json
import time
import uuid
import asyncio
import logging
from typing import Optional
from pathlib import Path

import websockets

from services.providers import SpeechToTextProvider, TranscriptionResult
from utils.provider_errors import ProviderError

logger = logging.getLogger(__name__)


class VolcengineSpeechToText(SpeechToTextProvider):
    """ç«å±±äº‘ASRæä¾›è€… - v3 API WebSocketå®žçŽ°"""
    
    def __init__(self, app_id: str, access_token: str):
        if not app_id or not access_token:
            raise ProviderError("ç«å±±äº‘ASRé…ç½®å‚æ•°ä¸å®Œæ•´")
        
        self.app_id = app_id
        self.access_token = access_token
        
        # v3 API WebSocketç«¯ç‚¹
        self.ws_url = "wss://openspeech.bytedance.com/api/v3/sauc/bigmodel_nostream"
        
        # æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
        self.supported_formats = ['.mp3', '.wav', '.flac', '.aac', '.m4a']
        self.max_file_size = 100 * 1024 * 1024  # 100MB
    
    def transcribe(self, audio_path: str, language: Optional[str] = None, 
                  prompt: Optional[str] = None) -> TranscriptionResult:
        """åŒæ­¥æŽ¥å£ï¼šè½¬å½•éŸ³é¢‘"""
        try:
            # åœ¨å¤šçº¿ç¨‹çŽ¯å¢ƒä¸­æ­£ç¡®å¤„ç†äº‹ä»¶å¾ªçŽ¯
            try:
                loop = asyncio.get_running_loop()
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, 
                                           self._transcribe_async(audio_path, language, prompt))
                    return future.result()
            except RuntimeError:
                # å½“å‰çº¿ç¨‹æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªçŽ¯
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    return loop.run_until_complete(
                        self._transcribe_async(audio_path, language, prompt)
                    )
                finally:
                    loop.close()
                    asyncio.set_event_loop(None)
        except Exception as e:
            logger.error(f"ASRè½¬å½•å¤±è´¥: {e}")
            raise ProviderError(f"ASRè½¬å½•å¤±è´¥: {str(e)}")
    
    async def _transcribe_async(self, audio_path: str, language: Optional[str], 
                               prompt: Optional[str]) -> TranscriptionResult:
        """å¼‚æ­¥è½¬å½•å®žçŽ° - v3 API"""
        if not os.path.exists(audio_path):
            raise ProviderError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        self._validate_audio_file(audio_path)
        
        logger.info(f"ðŸš€ å¼€å§‹ASRè½¬å½• (v3 API): {audio_path}")
        logger.info(f"ðŸ“ è¯­è¨€: {language or 'auto'}")
        
        try:
            # v3 APIä½¿ç”¨HTTP Headersè®¤è¯
            headers = {
                "X-Api-App-Key": self.app_id,
                "X-Api-Access-Key": self.access_token,
                "X-Api-Resource-Id": "volc.bigasr.sauc.bigmodel",
                "X-Api-Connect-Id": str(uuid.uuid4())
            }
            
            async with websockets.connect(
                self.ws_url,
                additional_headers=headers,
                max_size=10 * 1024 * 1024
            ) as websocket:
                
                # 1. å‘é€å¼€å§‹è¯·æ±‚ï¼ˆv3æ ¼å¼ï¼‰
                start_request = {
                    "user": {
                        "uid": str(uuid.uuid4())
                    },
                    "request": {
                        "model_name": "bigmodel",
                        "nbest": 1,
                        "show_utterances": False,
                        "enable_itn": True,
                        "enable_punc": True,
                        "enable_ddc": False,
                        "language": language or "zh"
                    },
                    "audio": {
                        "format": "wav",
                        "sample_rate": 16000,
                        "bits": 16,
                        "channel": 1
                    }
                }
                
                await websocket.send(json.dumps(start_request))
                logger.debug("ðŸ“¤ å‘é€v3å¼€å§‹è¯·æ±‚")
                
                # 2. å‘é€éŸ³é¢‘æ•°æ®ï¼ˆäºŒè¿›åˆ¶æµï¼‰
                chunk_size = 8192  # v3æŽ¨èçš„å—å¤§å°
                with open(audio_path, 'rb') as f:
                    bytes_sent = 0
                    while True:
                        chunk = f.read(chunk_size)
                        if not chunk:
                            break
                        
                        # ç›´æŽ¥å‘é€äºŒè¿›åˆ¶æ•°æ®
                        await websocket.send(chunk)
                        bytes_sent += len(chunk)
                        
                        # æŽ§åˆ¶å‘é€é€ŸçŽ‡
                        await asyncio.sleep(0.02)
                    
                    logger.debug(f"ðŸ“¤ éŸ³é¢‘å‘é€å®Œæˆ: {bytes_sent} å­—èŠ‚")
                
                # 3. å‘é€ç»“æŸä¿¡å·ï¼ˆç©ºäºŒè¿›åˆ¶æ•°æ®ï¼‰
                await websocket.send(b'')
                logger.debug("ðŸ“¤ å‘é€ç»“æŸä¿¡å·")
                
                # 4. æŽ¥æ”¶è½¬å½•ç»“æžœ
                transcription_text = ""
                full_response = None
                
                while True:
                    try:
                        response = await asyncio.wait_for(websocket.recv(), timeout=30.0)
                        
                        # è§£æžå“åº”
                        if isinstance(response, str):
                            data = json.loads(response)
                            logger.debug(f"ðŸ“¥ æ”¶åˆ°å“åº”: {data.get('message', '')}")
                            
                            # v3 APIå“åº”æ ¼å¼
                            if data.get("code") == 20000000:
                                # æˆåŠŸå“åº”
                                result = data.get("result", {})
                                
                                # æå–è½¬å½•æ–‡æœ¬
                                if "text" in result:
                                    transcription_text = result["text"]
                                    full_response = data
                                    logger.info(f"âœ… è½¬å½•æˆåŠŸ: {transcription_text[:50]}...")
                                    break
                                
                                # å¤„ç†åˆ†æ®µç»“æžœ
                                utterances = result.get("utterances", [])
                                for utterance in utterances:
                                    text = utterance.get("text", "")
                                    if text:
                                        transcription_text += text + " "
                                
                                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                                if data.get("is_final", False):
                                    logger.debug("âœ… è½¬å½•å®Œæˆ")
                                    break
                            
                            elif data.get("code") != 20000000 and data.get("code") is not None:
                                # é”™è¯¯å“åº”
                                error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
                                raise ProviderError(f"ASR APIé”™è¯¯ (code={data.get('code')}): {error_msg}")
                        
                        elif isinstance(response, bytes):
                            # æŸäº›å“åº”å¯èƒ½æ˜¯äºŒè¿›åˆ¶æ ¼å¼
                            logger.debug(f"ðŸ“¥ æ”¶åˆ°äºŒè¿›åˆ¶å“åº”: {len(response)} å­—èŠ‚")
                            
                    except asyncio.TimeoutError:
                        logger.warning("â±ï¸ æŽ¥æ”¶è¶…æ—¶")
                        break
                    except websockets.exceptions.ConnectionClosed:
                        logger.debug("ðŸ”Œ è¿žæŽ¥æ­£å¸¸å…³é—­")
                        break
                
                # 5. å¤„ç†ç»“æžœ
                if transcription_text:
                    # æ¸…ç†å¤šä½™çš„ç©ºæ ¼
                    transcription_text = ' '.join(transcription_text.split())
                    
                    return TranscriptionResult(
                        text=transcription_text,
                        language=language or "zh",
                        duration=self._estimate_duration(audio_path),
                        segments=[]  # v3 APIæš‚ä¸è¿”å›žè¯¦ç»†åˆ†æ®µ
                    )
                else:
                    # çœŸå®žæŠ¥é”™ï¼Œä¸ä½¿ç”¨å ä½ç¬¦
                    raise ProviderError("ASRè½¬å½•å¤±è´¥ï¼šæœªæ”¶åˆ°æœ‰æ•ˆè½¬å½•ç»“æžœ")
                    
        except websockets.exceptions.WebSocketException as e:
            logger.error(f"WebSocketé”™è¯¯: {e}")
            raise ProviderError(f"WebSocketè¿žæŽ¥å¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"ASRå¤„ç†é”™è¯¯: {e}")
            raise ProviderError(f"ASRå¤„ç†å¤±è´¥: {str(e)}")
    
    def _validate_audio_file(self, audio_path: str):
        """éªŒè¯éŸ³é¢‘æ–‡ä»¶"""
        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        file_ext = os.path.splitext(audio_path)[1].lower()
        if file_ext not in self.supported_formats:
            raise ProviderError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(audio_path)
        if file_size > self.max_file_size:
            raise ProviderError(f"æ–‡ä»¶å¤ªå¤§: {file_size} bytes (æœ€å¤§ {self.max_file_size} bytes)")
        
        if file_size == 0:
            raise ProviderError("éŸ³é¢‘æ–‡ä»¶ä¸ºç©º")
    
    def _estimate_duration(self, audio_path: str) -> float:
        """ä¼°ç®—éŸ³é¢‘æ—¶é•¿"""
        # ç®€å•ä¼°ç®—ï¼šåŸºäºŽæ–‡ä»¶å¤§å°
        file_size = os.path.getsize(audio_path)
        # å‡è®¾16kHz, 16bit, å•å£°é“
        bytes_per_second = 16000 * 2  # 32000 bytes/s
        return file_size / bytes_per_second
    
    def transcribe_with_timestamps(self, audio_path: str, language: Optional[str] = None,
                                 prompt: Optional[str] = None) -> TranscriptionResult:
        """è½¬å½•éŸ³é¢‘æ–‡ä»¶å¹¶èŽ·å–æ—¶é—´æˆ³ä¿¡æ¯"""
        return self.transcribe(audio_path, language, prompt)
    
    def detect_language(self, audio_path: str) -> str:
        """æ£€æµ‹éŸ³é¢‘è¯­è¨€"""
        try:
            result = self.transcribe(audio_path)
            return result.language or 'zh'
        except:
            return 'zh'  # é»˜è®¤ä¸­æ–‡
#!/usr/bin/env python3
"""
ç«å±±äº‘è¯­éŸ³è¯†åˆ«æœåŠ¡ - æ­£ç¡®å®žçŽ°ç‰ˆ
ä½¿ç”¨ç«å±±äº‘v3 APIå’Œæ­£ç¡®çš„WebSocketåè®®
"""

import os
import json
import time
import uuid
import asyncio
import logging
import base64
from typing import Optional
from pathlib import Path

import websockets

from services.providers import SpeechToTextProvider, TranscriptionResult
from utils.provider_errors import ProviderError

logger = logging.getLogger(__name__)


class VolcengineSpeechToText(SpeechToTextProvider):
    """ç«å±±äº‘ASRæä¾›è€… - v3 APIæ­£ç¡®å®žçŽ°"""
    
    def __init__(self, app_id: str, access_token: str):
        if not app_id or not access_token:
            raise ProviderError("ç«å±±äº‘ASRé…ç½®å‚æ•°ä¸å®Œæ•´")
        
        self.app_id = app_id
        self.access_token = access_token
        
        # ä½¿ç”¨æ­£ç¡®çš„v3ç«¯ç‚¹
        self.ws_url_bidirectional = "wss://openspeech.bytedance.com/api/v3/sauc/bigmodel"
        self.ws_url_streaming = "wss://openspeech.bytedance.com/api/v3/sauc/bigmodel_nostream"
        
        # æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
        self.supported_formats = ['.mp3', '.wav', '.flac', '.aac', '.m4a']
        self.max_file_size = 100 * 1024 * 1024  # 100MB
        
        # éŸ³é¢‘é…ç½®
        self.chunk_size = 3200  # 100-200mséŸ³é¢‘åŒ…å¤§å°
        self.chunk_duration = 0.1  # 100ms per chunk
    
    def transcribe(self, audio_path: str, language: Optional[str] = None, 
                  prompt: Optional[str] = None) -> TranscriptionResult:
        """åŒæ­¥æŽ¥å£ï¼šè½¬å½•éŸ³é¢‘"""
        try:
            # åœ¨å¤šçº¿ç¨‹çŽ¯å¢ƒä¸­æ­£ç¡®å¤„ç†äº‹ä»¶å¾ªçŽ¯
            try:
                # å°è¯•èŽ·å–å½“å‰çº¿ç¨‹çš„äº‹ä»¶å¾ªçŽ¯
                loop = asyncio.get_running_loop()
                # å¦‚æžœäº‹ä»¶å¾ªçŽ¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå™¨
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, 
                                           self._transcribe_async(audio_path, language, prompt))
                    return future.result()
            except RuntimeError:
                # å½“å‰çº¿ç¨‹æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªçŽ¯ï¼Œåˆ›å»ºæ–°çš„äº‹ä»¶å¾ªçŽ¯
                logger.debug("åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªçŽ¯ç”¨äºŽASRè½¬å½•")
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    return loop.run_until_complete(
                        self._transcribe_async(audio_path, language, prompt)
                    )
                finally:
                    loop.close()
                    # æ¸…ç†äº‹ä»¶å¾ªçŽ¯
                    asyncio.set_event_loop(None)
        except Exception as e:
            logger.error(f"ASRè½¬å½•å¤±è´¥: {e}")
            raise ProviderError(f"ASRè½¬å½•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å¤„ç†: {str(e)}")
    
    async def _transcribe_async(self, audio_path: str, language: Optional[str], 
                               prompt: Optional[str]) -> TranscriptionResult:
        """å¼‚æ­¥è½¬å½•å®žçŽ°"""
        if not os.path.exists(audio_path):
            raise ProviderError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        self._validate_audio_file(audio_path)
        
        logger.info(f"ðŸš€ å¼€å§‹ASRè½¬å½•: {audio_path}")
        logger.info(f"ðŸ“ è¯­è¨€: {language or 'zh'}")
        
        # ç”Ÿæˆè¿žæŽ¥ID
        connect_id = str(uuid.uuid4())
        
        # ä½¿ç”¨æ­£ç¡®çš„è®¤è¯headers
        headers = {
            "X-Api-App-Key": self.app_id,
            "X-Api-Access-Key": self.access_token,
            "X-Api-Resource-Id": "volc.bigasr.sauc.bigmodel",
            "X-Api-Connect-Id": connect_id
        }
        
        try:
            # ä½¿ç”¨æµå¼è¾“å…¥æ¨¡å¼ï¼ˆæ›´é«˜ç²¾åº¦ï¼‰
            async with websockets.connect(
                self.ws_url_streaming, 
                additional_headers=headers,
                max_size=10 * 1024 * 1024,
                ping_interval=20,
                ping_timeout=20,
                close_timeout=10
            ) as websocket:
                
                logger.info(f"âœ… WebSocketè¿žæŽ¥æˆåŠŸï¼Œè¿žæŽ¥ID: {connect_id}")
                
                # 1. å‘é€å¼€å§‹è¯·æ±‚ï¼ˆJSONæ ¼å¼ï¼‰
                start_request = {
                    "user": {
                        "uid": "user_123"
                    },
                    "audio": {
                        "format": "wav",  # éŸ³é¢‘æ ¼å¼
                        "rate": 16000,    # é‡‡æ ·çŽ‡
                        "bits": 16,       # ä½æ·±
                        "channel": 1      # å£°é“æ•°
                    },
                    "request": {
                        "reqid": str(uuid.uuid4()),
                        "model_name": "bigmodel",
                        "enable_punc": True,        # å¯ç”¨æ ‡ç‚¹
                        "enable_itn": True,         # å¯ç”¨æ•°å­—è½¬æ¢
                        "language": language or "zh"  # è¯­è¨€è®¾ç½®
                    }
                }
                
                await websocket.send(json.dumps(start_request))
                logger.debug("ðŸ“¤ å‘é€å¼€å§‹è¯·æ±‚")
                
                # 2. å‘é€éŸ³é¢‘æ•°æ®
                await self._send_audio_data(websocket, audio_path)
                
                # 3. ç­‰å¾…å¹¶æŽ¥æ”¶è½¬å½•ç»“æžœ
                transcription_text = await self._receive_transcription_result(websocket)
                
                # 4. è¿”å›žç»“æžœ
                if transcription_text:
                    logger.info(f"âœ… ASRè½¬å½•æˆåŠŸ: {transcription_text[:50]}...")
                    return TranscriptionResult(
                        text=transcription_text,
                        language=language or "zh",
                        duration=self._estimate_duration(audio_path),
                        segments=[]
                    )
                else:
                    raise ProviderError("ASRè½¬å½•å¤±è´¥ï¼šæœªæ”¶åˆ°æœ‰æ•ˆè½¬å½•ç»“æžœ")
                    
        except websockets.exceptions.WebSocketException as e:
            logger.error(f"WebSocketè¿žæŽ¥é”™è¯¯: {e}")
            raise ProviderError(f"ASRè¿žæŽ¥å¤±è´¥: {str(e)}")
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æžé”™è¯¯: {e}")
            raise ProviderError(f"ASRå“åº”è§£æžå¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"ASRå¤„ç†é”™è¯¯: {e}")
            raise ProviderError(f"ASRå¤„ç†å¤±è´¥: {str(e)}")
    
    async def _send_audio_data(self, websocket, audio_path: str):
        """å‘é€éŸ³é¢‘æ•°æ®"""
        logger.debug("ðŸ“¤ å¼€å§‹å‘é€éŸ³é¢‘æ•°æ®")
        
        file_size = os.path.getsize(audio_path)
        sent_bytes = 0
        
        with open(audio_path, 'rb') as f:
            while True:
                chunk = f.read(self.chunk_size)
                if not chunk:
                    break
                
                # å‘é€éŸ³é¢‘å—ï¼ˆäºŒè¿›åˆ¶æ ¼å¼ï¼‰
                await websocket.send(chunk)
                sent_bytes += len(chunk)
                
                # æŽ§åˆ¶å‘é€é€ŸçŽ‡ï¼ˆæ¨¡æ‹Ÿ100mséŸ³é¢‘åŒ…ï¼‰
                await asyncio.sleep(self.chunk_duration)
                
                # è¿›åº¦æ—¥å¿—
                progress = (sent_bytes / file_size) * 100
                if sent_bytes % (self.chunk_size * 10) == 0:  # æ¯1ç§’æ—¥å¿—ä¸€æ¬¡
                    logger.debug(f"ðŸ“¤ å‘é€è¿›åº¦: {progress:.1f}% ({sent_bytes}/{file_size})")
        
        logger.debug(f"âœ… éŸ³é¢‘å‘é€å®Œæˆ: {sent_bytes} bytes")
    
    async def _receive_transcription_result(self, websocket) -> str:
        """æŽ¥æ”¶å¹¶è§£æžè½¬å½•ç»“æžœ"""
        logger.debug("ðŸ“¥ å¼€å§‹æŽ¥æ”¶è½¬å½•ç»“æžœ")
        
        transcription_text = ""
        timeout_count = 0
        max_timeouts = 3
        
        while True:
            try:
                # ç­‰å¾…æœåŠ¡å™¨å“åº”
                response = await asyncio.wait_for(websocket.recv(), timeout=15.0)
                timeout_count = 0  # é‡ç½®è¶…æ—¶è®¡æ•°
                
                # è§£æžå“åº”
                if isinstance(response, str):
                    data = json.loads(response)
                    logger.debug(f"ðŸ“¥ æ”¶åˆ°å“åº”: {json.dumps(data, ensure_ascii=False)[:200]}...")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                    if "error" in data:
                        error_msg = data.get("error", {})
                        raise ProviderError(f"ASRæœåŠ¡é”™è¯¯: {error_msg}")
                    
                    # å¤„ç†è¯†åˆ«ç»“æžœ
                    if "result" in data:
                        result = data["result"]
                        if isinstance(result, dict) and "text" in result:
                            text = result["text"]
                            if text:
                                transcription_text += text
                                logger.debug(f"ðŸ“ æŽ¥æ”¶æ–‡æœ¬: {text}")
                    
                    # æ£€æŸ¥æ˜¯å¦ç»“æŸ
                    if data.get("is_end", False) or data.get("message") == "success":
                        logger.debug("âœ… è½¬å½•å®Œæˆ")
                        break
                        
                elif isinstance(response, bytes):
                    # å¤„ç†äºŒè¿›åˆ¶å“åº”ï¼ˆå¦‚æžœæœ‰çš„è¯ï¼‰
                    logger.debug(f"ðŸ“¥ æ”¶åˆ°äºŒè¿›åˆ¶å“åº”: {len(response)} bytes")
                    
            except asyncio.TimeoutError:
                timeout_count += 1
                logger.debug(f"â±ï¸ æŽ¥æ”¶è¶…æ—¶ ({timeout_count}/{max_timeouts})")
                
                if timeout_count >= max_timeouts:
                    logger.warning("å¤šæ¬¡æŽ¥æ”¶è¶…æ—¶ï¼Œç»“æŸç­‰å¾…")
                    break
                    
            except websockets.exceptions.ConnectionClosed:
                logger.debug("ðŸ”Œ è¿žæŽ¥å…³é—­")
                break
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æžå¤±è´¥: {e}")
                continue
        
        return transcription_text.strip()
    
    def _validate_audio_file(self, audio_path: str):
        """éªŒè¯éŸ³é¢‘æ–‡ä»¶"""
        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        file_ext = os.path.splitext(audio_path)[1].lower()
        if file_ext not in self.supported_formats:
            raise ProviderError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(audio_path)
        if file_size > self.max_file_size:
            raise ProviderError(f"æ–‡ä»¶å¤ªå¤§: {file_size} bytes (æœ€å¤§ {self.max_file_size} bytes)")
        
        if file_size == 0:
            raise ProviderError("éŸ³é¢‘æ–‡ä»¶ä¸ºç©º")
    
    def _estimate_duration(self, audio_path: str) -> float:
        """ä¼°ç®—éŸ³é¢‘æ—¶é•¿"""
        # åŸºäºŽæ–‡ä»¶å¤§å°çš„ç®€å•ä¼°ç®—
        file_size = os.path.getsize(audio_path)
        # å‡è®¾16kHz, 16bit, å•å£°é“
        bytes_per_second = 16000 * 2
        return file_size / bytes_per_second
    
    def transcribe_with_timestamps(self, audio_path: str, language: Optional[str] = None,
                                 prompt: Optional[str] = None) -> TranscriptionResult:
        """è½¬å½•éŸ³é¢‘æ–‡ä»¶å¹¶èŽ·å–æ—¶é—´æˆ³ä¿¡æ¯"""
        return self.transcribe(audio_path, language, prompt)
    
    def detect_language(self, audio_path: str) -> str:
        """æ£€æµ‹éŸ³é¢‘è¯­è¨€"""
        try:
            result = self.transcribe(audio_path)
            return result.language or 'zh'
        except:
            return 'zh'  # é»˜è®¤ä¸­æ–‡
#!/usr/bin/env python3
"""
éŸ³é¢‘è§†é¢‘ç¿»è¯‘ç³»ç»Ÿä¸»å…¥å£
æä¾›å‘½ä»¤è¡Œæ¥å£å’Œä½œä¸šç®¡ç†åŠŸèƒ½
"""

import os
import sys
import argparse
import time
import json
from typing import Optional, List, Dict, Any
from dataclasses import asdict

# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—å‰ï¼‰
from dotenv import load_dotenv
load_dotenv()

from services.integrated_pipeline import IntegratedPipeline, PipelineConfig, PipelineResult
from services.output_generator import OutputConfig
from models.core import ProcessingStage
from utils.error_handler import handle_error, ErrorContext


class AudioVideoTranslationApp:
    """éŸ³é¢‘è§†é¢‘ç¿»è¯‘åº”ç”¨ä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨"""
        self.pipeline: Optional[IntegratedPipeline] = None
        self.config_file = "config.json"
        self.default_config = {
            "target_language": "zh-CN",
            "voice_model": "alloy",
            "preserve_background_audio": True,
            "output_directory": "./output",
            "file_naming_pattern": "{name}_translated_{timestamp}",
            "audio_format": "mp3",
            "video_format": "mp4",
            "enable_fault_tolerance": True,
            "max_retries": 3
        }
    
    def load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = config_path or self.config_file
        
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                print(f"âœ“ å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
                return {**self.default_config, **config}
            except Exception as e:
                print(f"âš  é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {str(e)}")
        
        return self.default_config.copy()
    
    def save_config(self, config: Dict[str, Any], config_path: Optional[str] = None):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        config_file = config_path or self.config_file
        
        try:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            print(f"âœ“ é…ç½®å·²ä¿å­˜åˆ°: {config_file}")
        except Exception as e:
            print(f"âœ— é…ç½®ä¿å­˜å¤±è´¥: {str(e)}")
    
    def initialize_pipeline(self, config: Dict[str, Any]) -> bool:
        """åˆå§‹åŒ–å¤„ç†ç®¡é“"""
        try:
            # åˆ›å»ºè¾“å‡ºé…ç½®
            output_config = OutputConfig(
                output_directory=config.get("output_directory", "./output"),
                file_naming_pattern=config.get("file_naming_pattern", "{name}_translated_{timestamp}"),
                audio_format=config.get("audio_format", "mp3"),
                video_format=config.get("video_format", "mp4"),
                overwrite_existing=config.get("overwrite_existing", False)
            )
            
            # åˆ›å»ºç®¡é“é…ç½®
            pipeline_config = PipelineConfig(
                target_language=config.get("target_language", "zh-CN"),
                voice_model=config.get("voice_model", "alloy"),
                preserve_background_audio=config.get("preserve_background_audio", True),
                output_config=output_config,
                enable_fault_tolerance=config.get("enable_fault_tolerance", True),
                max_retries=config.get("max_retries", 3),
                progress_callback=self._progress_callback
            )
            
            # åˆå§‹åŒ–ç®¡é“
            self.pipeline = IntegratedPipeline(pipeline_config)
            print("âœ“ å¤„ç†ç®¡é“åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            error_context = ErrorContext(operation="initialize_pipeline")
            processed_error = handle_error(e, error_context)
            print(f"âœ— ç®¡é“åˆå§‹åŒ–å¤±è´¥: {processed_error.user_message}")
            return False
    
    def _progress_callback(self, job_id: str, progress: float, message: str):
        """è¿›åº¦å›è°ƒå‡½æ•°"""
        print(f"[{job_id[:8]}] {progress:.1%} - {message}")
    
    def process_file(self, file_path: str, target_language: Optional[str] = None) -> Optional[str]:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶
        
        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            target_language: ç›®æ ‡è¯­è¨€ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ä½œä¸šIDï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not self.pipeline:
            print("âœ— ç®¡é“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œ init å‘½ä»¤")
            return None
        
        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„ï¼šæ”¯æŒHTTP URLå’Œæœ¬åœ°æ–‡ä»¶
        if not file_path.startswith('http') and not os.path.exists(file_path):
            print(f"âœ— æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        
        try:
            print(f"ğŸš€ å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")
            
            job_id = self.pipeline.process_file(file_path, target_language)
            print(f"âœ“ ä½œä¸šå·²åˆ›å»ºï¼ŒID: {job_id}")
            
            return job_id
            
        except Exception as e:
            error_context = ErrorContext(
                file_path=file_path,
                operation="process_file"
            )
            processed_error = handle_error(e, error_context)
            print(f"âœ— æ–‡ä»¶å¤„ç†å¤±è´¥: {processed_error.user_message}")
            return None
    
    def get_job_status(self, job_id: str) -> bool:
        """è·å–ä½œä¸šçŠ¶æ€"""
        if not self.pipeline:
            print("âœ— ç®¡é“æœªåˆå§‹åŒ–")
            return False
        
        try:
            job = self.pipeline.get_job_status(job_id)
            if not job:
                print(f"âœ— ä½œä¸šä¸å­˜åœ¨: {job_id}")
                return False
            
            # æ˜¾ç¤ºä½œä¸šä¿¡æ¯
            print(f"\nğŸ“‹ ä½œä¸šçŠ¶æ€ [{job_id}]")
            print(f"æ–‡ä»¶è·¯å¾„: {job.file_path}")
            print(f"ç›®æ ‡è¯­è¨€: {job.target_language}")
            print(f"å½“å‰é˜¶æ®µ: {job.current_stage.value}")
            print(f"åˆ›å»ºæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(job.created_at))}")
            
            if job.processing_time > 0:
                print(f"å¤„ç†æ—¶é—´: {job.processing_time:.1f}ç§’")
            
            if hasattr(job, 'error_message') and job.error_message:
                print(f"é”™è¯¯ä¿¡æ¯: {job.error_message}")
            
            # æ˜¾ç¤ºè¿›åº¦
            if job.current_stage == ProcessingStage.COMPLETED:
                print("ğŸ‰ å¤„ç†å®Œæˆ!")
                if hasattr(job, 'output_file_path') and job.output_file_path:
                    print(f"è¾“å‡ºæ–‡ä»¶: {job.output_file_path}")
            elif job.current_stage == ProcessingStage.FAILED:
                print("âŒ å¤„ç†å¤±è´¥")
            else:
                print("â³ æ­£åœ¨å¤„ç†ä¸­...")
            
            return True
            
        except Exception as e:
            error_context = ErrorContext(
                job_id=job_id,
                operation="get_job_status"
            )
            processed_error = handle_error(e, error_context)
            print(f"âœ— è·å–çŠ¶æ€å¤±è´¥: {processed_error.user_message}")
            return False
    
    def list_jobs(self) -> bool:
        """åˆ—å‡ºæ‰€æœ‰ä½œä¸š"""
        if not self.pipeline:
            print("âœ— ç®¡é“æœªåˆå§‹åŒ–")
            return False
        
        try:
            # è·å–æ´»è·ƒä½œä¸š
            active_jobs = self.pipeline.list_active_jobs()
            
            # è·å–æ‰€æœ‰ä½œä¸š
            all_jobs = []
            for job_id in self.pipeline.job_manager.jobs:
                job = self.pipeline.job_manager.get_job(job_id)
                if job:
                    all_jobs.append((job_id, job))
            
            if not all_jobs:
                print("ğŸ“‹ æš‚æ— ä½œä¸š")
                return True
            
            print(f"\nğŸ“‹ ä½œä¸šåˆ—è¡¨ (å…± {len(all_jobs)} ä¸ª)")
            print("-" * 80)
            print(f"{'ä½œä¸šID':<12} {'çŠ¶æ€':<15} {'æ–‡ä»¶':<30} {'åˆ›å»ºæ—¶é—´':<20}")
            print("-" * 80)
            
            for job_id, job in sorted(all_jobs, key=lambda x: x[1].created_at, reverse=True):
                status = "ğŸ”„ å¤„ç†ä¸­" if job_id in active_jobs else self._get_status_emoji(job.current_stage)
                file_name = os.path.basename(job.file_path)
                create_time = time.strftime('%m-%d %H:%M', time.localtime(job.created_at))
                
                print(f"{job_id[:12]:<12} {status:<15} {file_name[:30]:<30} {create_time:<20}")
            
            return True
            
        except Exception as e:
            error_context = ErrorContext(operation="list_jobs")
            processed_error = handle_error(e, error_context)
            print(f"âœ— åˆ—å‡ºä½œä¸šå¤±è´¥: {processed_error.user_message}")
            return False
    
    def _get_status_emoji(self, stage: ProcessingStage) -> str:
        """è·å–çŠ¶æ€è¡¨æƒ…ç¬¦å·"""
        status_map = {
            ProcessingStage.PENDING: "â³ ç­‰å¾…ä¸­",
            ProcessingStage.FILE_VALIDATION: "ğŸ” éªŒè¯ä¸­",
            ProcessingStage.AUDIO_EXTRACTION: "ğŸµ æå–éŸ³é¢‘",
            ProcessingStage.SPEECH_TO_TEXT: "ğŸ“ è½¬æ–‡æœ¬",
            ProcessingStage.TEXT_TRANSLATION: "ğŸŒ ç¿»è¯‘ä¸­",
            ProcessingStage.TEXT_TO_SPEECH: "ğŸ—£ï¸ åˆæˆè¯­éŸ³",
            ProcessingStage.AUDIO_SYNC: "ğŸ”„ åŒæ­¥ä¸­",
            ProcessingStage.VIDEO_ASSEMBLY: "ğŸ¬ ç»„è£…ä¸­",
            ProcessingStage.OUTPUT_GENERATION: "ğŸ“¦ ç”Ÿæˆè¾“å‡º",
            ProcessingStage.COMPLETED: "âœ… å·²å®Œæˆ",
            ProcessingStage.FAILED: "âŒ å¤±è´¥"
        }
        return status_map.get(stage, "â“ æœªçŸ¥")
    
    def cancel_job(self, job_id: str) -> bool:
        """å–æ¶ˆä½œä¸š"""
        if not self.pipeline:
            print("âœ— ç®¡é“æœªåˆå§‹åŒ–")
            return False
        
        try:
            success = self.pipeline.cancel_job(job_id)
            if success:
                print(f"âœ“ ä½œä¸šå·²å–æ¶ˆ: {job_id}")
            else:
                print(f"âœ— ä½œä¸šå–æ¶ˆå¤±è´¥æˆ–ä¸å­˜åœ¨: {job_id}")
            
            return success
            
        except Exception as e:
            error_context = ErrorContext(
                job_id=job_id,
                operation="cancel_job"
            )
            processed_error = handle_error(e, error_context)
            print(f"âœ— å–æ¶ˆä½œä¸šå¤±è´¥: {processed_error.user_message}")
            return False
    
    def wait_for_completion(self, job_id: str, timeout: int = 300) -> bool:
        """ç­‰å¾…ä½œä¸šå®Œæˆ"""
        if not self.pipeline:
            print("âœ— ç®¡é“æœªåˆå§‹åŒ–")
            return False
        
        print(f"â³ ç­‰å¾…ä½œä¸šå®Œæˆ: {job_id} (è¶…æ—¶: {timeout}ç§’)")
        
        start_time = time.time()
        last_stage = None
        
        while time.time() - start_time < timeout:
            try:
                job = self.pipeline.get_job_status(job_id)
                if not job:
                    print(f"âœ— ä½œä¸šä¸å­˜åœ¨: {job_id}")
                    return False
                
                # æ˜¾ç¤ºé˜¶æ®µå˜åŒ–
                if job.current_stage != last_stage:
                    print(f"ğŸ“ {self._get_status_emoji(job.current_stage)}")
                    last_stage = job.current_stage
                
                # æ£€æŸ¥å®ŒæˆçŠ¶æ€
                if job.current_stage == ProcessingStage.COMPLETED:
                    result = self.pipeline.get_processing_result(job_id)
                    print(f"ğŸ‰ ä½œä¸šå®Œæˆ! è¾“å‡ºæ–‡ä»¶: {result.output_file_path}")
                    return True
                elif job.current_stage == ProcessingStage.FAILED:
                    print(f"âŒ ä½œä¸šå¤±è´¥")
                    if hasattr(job, 'error_message') and job.error_message:
                        print(f"é”™è¯¯ä¿¡æ¯: {job.error_message}")
                    return False
                
                time.sleep(2)  # ç­‰å¾…2ç§’åé‡æ–°æ£€æŸ¥
                
            except KeyboardInterrupt:
                print(f"\nâš  ç”¨æˆ·ä¸­æ–­ç­‰å¾…")
                return False
            except Exception as e:
                error_context = ErrorContext(
                    job_id=job_id,
                    operation="wait_for_completion"
                )
                processed_error = handle_error(e, error_context)
                print(f"âœ— ç­‰å¾…è¿‡ç¨‹ä¸­å‡ºé”™: {processed_error.user_message}")
                return False
        
        print(f"â° ç­‰å¾…è¶…æ—¶ ({timeout}ç§’)")
        return False
    
    def show_system_metrics(self) -> bool:
        """æ˜¾ç¤ºç³»ç»ŸæŒ‡æ ‡"""
        if not self.pipeline:
            print("âœ— ç®¡é“æœªåˆå§‹åŒ–")
            return False
        
        try:
            metrics = self.pipeline.get_system_metrics()
            
            print("\nğŸ“Š ç³»ç»ŸæŒ‡æ ‡")
            print("-" * 50)
            print(f"æ´»è·ƒä½œä¸šæ•°é‡: {metrics['active_jobs_count']}")
            print(f"æ€»å¤„ç†ä½œä¸šæ•°: {metrics['total_jobs_processed']}")
            
            # é”™è¯¯ç»Ÿè®¡
            error_stats = metrics['error_statistics']
            if error_stats['total_errors'] > 0:
                print(f"\né”™è¯¯ç»Ÿè®¡:")
                print(f"  æ€»é”™è¯¯æ•°: {error_stats['total_errors']}")
                if error_stats['by_category']:
                    print("  æŒ‰åˆ†ç±»:")
                    for category, count in error_stats['by_category'].items():
                        print(f"    {category}: {count}")
            
            return True
            
        except Exception as e:
            error_context = ErrorContext(operation="show_system_metrics")
            processed_error = handle_error(e, error_context)
            print(f"âœ— è·å–æŒ‡æ ‡å¤±è´¥: {processed_error.user_message}")
            return False
    
    def shutdown(self):
        """å…³é—­åº”ç”¨"""
        if self.pipeline:
            print("ğŸ”„ æ­£åœ¨å…³é—­å¤„ç†ç®¡é“...")
            self.pipeline.shutdown()
            print("âœ“ åº”ç”¨å·²å…³é—­")


def create_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="éŸ³é¢‘è§†é¢‘ç¿»è¯‘ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åˆå§‹åŒ–ç³»ç»Ÿ
  python main.py init
  
  # å¤„ç†è§†é¢‘æ–‡ä»¶
  python main.py process input.mp4 --language zh-CN
  
  # å¤„ç†éŸ³é¢‘æ–‡ä»¶å¹¶ç­‰å¾…å®Œæˆ
  python main.py process audio.mp3 --wait
  
  # æŸ¥çœ‹ä½œä¸šçŠ¶æ€
  python main.py status JOB_ID
  
  # åˆ—å‡ºæ‰€æœ‰ä½œä¸š
  python main.py list
  
  # å–æ¶ˆä½œä¸š
  python main.py cancel JOB_ID
  
  # æŸ¥çœ‹ç³»ç»ŸæŒ‡æ ‡
  python main.py metrics
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # init å‘½ä»¤
    init_parser = subparsers.add_parser('init', help='åˆå§‹åŒ–ç³»ç»Ÿ')
    init_parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„', default='config.json')
    
    # process å‘½ä»¤
    process_parser = subparsers.add_parser('process', help='å¤„ç†æ–‡ä»¶')
    process_parser.add_argument('file', help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    process_parser.add_argument('--language', '-l', help='ç›®æ ‡è¯­è¨€ (ä¾‹å¦‚: zh-CN, en, es)', default='zh-CN')
    process_parser.add_argument('--wait', '-w', action='store_true', help='ç­‰å¾…å¤„ç†å®Œæˆ')
    process_parser.add_argument('--timeout', '-t', type=int, default=300, help='ç­‰å¾…è¶…æ—¶æ—¶é—´(ç§’)')
    
    # status å‘½ä»¤
    status_parser = subparsers.add_parser('status', help='æŸ¥çœ‹ä½œä¸šçŠ¶æ€')
    status_parser.add_argument('job_id', help='ä½œä¸šID')
    
    # list å‘½ä»¤
    subparsers.add_parser('list', help='åˆ—å‡ºæ‰€æœ‰ä½œä¸š')
    
    # cancel å‘½ä»¤
    cancel_parser = subparsers.add_parser('cancel', help='å–æ¶ˆä½œä¸š')
    cancel_parser.add_argument('job_id', help='ä½œä¸šID')
    
    # wait å‘½ä»¤
    wait_parser = subparsers.add_parser('wait', help='ç­‰å¾…ä½œä¸šå®Œæˆ')
    wait_parser.add_argument('job_id', help='ä½œä¸šID')
    wait_parser.add_argument('--timeout', '-t', type=int, default=300, help='è¶…æ—¶æ—¶é—´(ç§’)')
    
    # metrics å‘½ä»¤
    subparsers.add_parser('metrics', help='æ˜¾ç¤ºç³»ç»ŸæŒ‡æ ‡')
    
    # config å‘½ä»¤
    config_parser = subparsers.add_parser('config', help='é…ç½®ç®¡ç†')
    config_subparsers = config_parser.add_subparsers(dest='config_action', help='é…ç½®æ“ä½œ')
    
    config_subparsers.add_parser('show', help='æ˜¾ç¤ºå½“å‰é…ç½®')
    
    set_parser = config_subparsers.add_parser('set', help='è®¾ç½®é…ç½®é¡¹')
    set_parser.add_argument('key', help='é…ç½®é”®')
    set_parser.add_argument('value', help='é…ç½®å€¼')
    
    return parser


def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    app = AudioVideoTranslationApp()
    
    try:
        if args.command == 'init':
            print("ğŸš€ åˆå§‹åŒ–éŸ³é¢‘è§†é¢‘ç¿»è¯‘ç³»ç»Ÿ...")
            config = app.load_config(getattr(args, 'config', None))
            if app.initialize_pipeline(config):
                app.save_config(config, getattr(args, 'config', None))
                print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")
            else:
                print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
                sys.exit(1)
        
        elif args.command == 'process':
            config = app.load_config()
            if not app.initialize_pipeline(config):
                sys.exit(1)
            
            job_id = app.process_file(args.file, args.language)
            if job_id and args.wait:
                app.wait_for_completion(job_id, args.timeout)
        
        elif args.command == 'status':
            config = app.load_config()
            if not app.initialize_pipeline(config):
                sys.exit(1)
            
            app.get_job_status(args.job_id)
        
        elif args.command == 'list':
            config = app.load_config()
            if not app.initialize_pipeline(config):
                sys.exit(1)
            
            app.list_jobs()
        
        elif args.command == 'cancel':
            config = app.load_config()
            if not app.initialize_pipeline(config):
                sys.exit(1)
            
            app.cancel_job(args.job_id)
        
        elif args.command == 'wait':
            config = app.load_config()
            if not app.initialize_pipeline(config):
                sys.exit(1)
            
            app.wait_for_completion(args.job_id, args.timeout)
        
        elif args.command == 'metrics':
            config = app.load_config()
            if not app.initialize_pipeline(config):
                sys.exit(1)
            
            app.show_system_metrics()
        
        elif args.command == 'config':
            if args.config_action == 'show':
                config = app.load_config()
                print("\nğŸ“‹ å½“å‰é…ç½®:")
                print(json.dumps(config, indent=2, ensure_ascii=False))
            
            elif args.config_action == 'set':
                config = app.load_config()
                
                # å°è¯•è§£æå€¼çš„ç±»å‹
                value = args.value
                if value.lower() in ('true', 'false'):
                    value = value.lower() == 'true'
                elif value.isdigit():
                    value = int(value)
                elif value.replace('.', '').isdigit():
                    value = float(value)
                
                config[args.key] = value
                app.save_config(config)
                print(f"âœ“ å·²è®¾ç½® {args.key} = {value}")
            
            else:
                parser.parse_args(['config', '--help'])
        
        else:
            parser.print_help()
    
    except KeyboardInterrupt:
        print("\nâš  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        error_context = ErrorContext(operation="main")
        processed_error = handle_error(e, error_context)
        print(f"âŒ åº”ç”¨é”™è¯¯: {processed_error.user_message}")
        sys.exit(1)
    finally:
        app.shutdown()


if __name__ == "__main__":
    main()